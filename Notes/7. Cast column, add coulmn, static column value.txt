# spark session
from pyspark.sql import SparkSession

spark = (
    SparkSession
    .builder
    .appName("Spark Introduction")  # name of our appication
    .master("local[*]")   # master is where is going to be executed.
    .getOrCreate() 
)

emp_data = [
    ["001", "101", "Joe Goldberg", "30", "Male", "50000", "2015-01-01"],
    ["002", "105", "Dwight Schrute", "40", "Male", "90000", "2015-08-11"],
    ["003", "107", "Marianne Bellamy", "320", "Female", "10000", "2025-03-22"],
    ["004", "102", "Monica Gellar", "26", "Female", "75000", "2017-09-21"],
    ["005", "103", "Joey Tribianni", "32", "Male", "5000", "2017-10-18"],
    ["006", "104", "Chandler Bing", "31", "Male", "100000", "2017-08-13"],
    ["007", "105", "Ross Gellar", "30", "Male", "150000", "2017-06-26"],
    ["008", "106", "Rachel Green", "29", "Female", "50000", "2017-08-21"],
    ["009", "107", "Pheebi Buffay", "30", "Female", "10000", "2017-10-29"],
    ["010", "101", "Peach Salinger", "32", "Female", "200000", "2019-01-20"],
    ["011", "102", "Michael Scott", "40", "Male", "80000", "2011-11-10"],
    ["012", "103", "Donald Draper", "35", "Male", "90000", "2014-12-23"],
    ["013", "104", "Roger Sterling", "60", "Male", "300000", "2000-11-21"]
]

emp_schema = "employee_id string, department_id string, name string, age string, gender string, salary string, hire_date string"

# Create emp DataFrame

emp = spark.createDataFrame(data=emp_data, schema=emp_schema)

# Show Data (ACTION)

emp.show()

-- Now let's validate the schema for the employee data.
-- Schema is the metadata that defines the name and the type of the columns.

# Schema for emp

emp.printSchema()

root
 |-- employee_id: string (nullable = true)
 |-- department_id: string (nullable = true)
 |-- name: string (nullable = true)
 |-- age: string (nullable = true)
 |-- gender: string (nullable = true)
 |-- salary: string (nullable = true)
 |-- hire_date: string (nullable = true)


-- Previously, we have used expr() for the casting.
-- But here we r going to use pyspark dataframe api provided by the pyspark
   sql functions module.

# casting column
# select employee_id, name, age, cast("salary as double") as salary from emp

from pyspark.sql.functions import col, cast

emp_casted = emp.select("employee_id", "name", "age", col("salary").cast("double"))

emp_casted.printSchema()

root
 |-- employee_id: string (nullable = true)
 |-- name: string (nullable = true)
 |-- age: string (nullable = true)
 |-- salary: double (nullable = true)

-- Spark provides withColumn() to create new column or override existing column.

# Adding columns
# select employee_id, name, age, salary, (salary *0.2) as tax from emp_casted

emp_taxed = emp_casted.withColumn("tax", col("salary")*0.2)

emp_taxed.show()

+-----------+----------------+---+--------+-------+
|employee_id|            name|age|  salary|    tax|
+-----------+----------------+---+--------+-------+
|        001|    Joe Goldberg| 30| 50000.0|10000.0|
|        002|  Dwight Schrute| 40| 90000.0|18000.0|
|        003|Marianne Bellamy|320| 10000.0| 2000.0|
|        004|   Monica Gellar| 26| 75000.0|15000.0|
|        005|  Joey Tribianni| 32|  5000.0| 1000.0|
|        006|   Chandler Bing| 31|100000.0|20000.0|
|        007|     Ross Gellar| 30|150000.0|30000.0|
|        008|    Rachel Green| 29| 50000.0|10000.0|
|        009|   Pheebi Buffay| 30| 10000.0| 2000.0|
|        010|  Peach Salinger| 32|200000.0|40000.0|
|        011|   Michael Scott| 40| 80000.0|16000.0|
|        012|   Donald Draper| 35| 90000.0|18000.0|
|        013|  Roger Sterling| 60|300000.0|60000.0|
+-----------+----------------+---+--------+-------+

-- Adding static value columns : Spark provides lit() to create a distributed 
   static column.

# literals
# select employee_id, name, age, salary, tax, 1 as columnOne, 
# 'two' as columnTwo from emp_taxed;

from pyspark.sql.functions import lit

emp_new_cols = emp_taxed.withColumn("columnOne", lit(1))
                        .withColumn("columnTwo", lit("Two"))

emp_new_cols.show()

+-----------+----------------+---+--------+-------+---------+---------+
|employee_id|            name|age|  salary|    tax|columnOne|columnTwo|
+-----------+----------------+---+--------+-------+---------+---------+
|        001|    Joe Goldberg| 30| 50000.0|10000.0|        1|      Two|
|        002|  Dwight Schrute| 40| 90000.0|18000.0|        1|      Two|
|        003|Marianne Bellamy|320| 10000.0| 2000.0|        1|      Two|
|        004|   Monica Gellar| 26| 75000.0|15000.0|        1|      Two|
|        005|  Joey Tribianni| 32|  5000.0| 1000.0|        1|      Two|
|        006|   Chandler Bing| 31|100000.0|20000.0|        1|      Two|
|        007|     Ross Gellar| 30|150000.0|30000.0|        1|      Two|
|        008|    Rachel Green| 29| 50000.0|10000.0|        1|      Two|
|        009|   Pheebi Buffay| 30| 10000.0| 2000.0|        1|      Two|
|        010|  Peach Salinger| 32|200000.0|40000.0|        1|      Two|
|        011|   Michael Scott| 40| 80000.0|16000.0|        1|      Two|
|        012|   Donald Draper| 35| 90000.0|18000.0|        1|      Two|
|        013|  Roger Sterling| 60|300000.0|60000.0|        1|      Two|
+-----------+----------------+---+--------+-------+---------+---------+

-- What if we want to add 10 columns at a time ? See it in bonus tip.

-- Rename existing columns : Spark provides withColumnRenamed() to the same.

# Renaming columns
# select employee_id as emp_id, name, age, salary, tax, columnOne, columnTwo from emp_new_cols;

emp_1 = emp_new_cols.withColumnRenamed("employee_id", "emp_id")
emp_1.show()

+------+----------------+---+--------+-------+---------+---------+
|emp_id|            name|age|  salary|    tax|columnOne|columnTwo|
+------+----------------+---+--------+-------+---------+---------+
|   001|    Joe Goldberg| 30| 50000.0|10000.0|        1|      Two|
|   002|  Dwight Schrute| 40| 90000.0|18000.0|        1|      Two|
|   003|Marianne Bellamy|320| 10000.0| 2000.0|        1|      Two|
|   004|   Monica Gellar| 26| 75000.0|15000.0|        1|      Two|
|   005|  Joey Tribianni| 32|  5000.0| 1000.0|        1|      Two|
|   006|   Chandler Bing| 31|100000.0|20000.0|        1|      Two|
|   007|     Ross Gellar| 30|150000.0|30000.0|        1|      Two|
|   008|    Rachel Green| 29| 50000.0|10000.0|        1|      Two|
|   009|   Pheebi Buffay| 30| 10000.0| 2000.0|        1|      Two|
|   010|  Peach Salinger| 32|200000.0|40000.0|        1|      Two|
|   011|   Michael Scott| 40| 80000.0|16000.0|        1|      Two|
|   012|   Donald Draper| 35| 90000.0|18000.0|        1|      Two|
|   013|  Roger Sterling| 60|300000.0|60000.0|        1|      Two|
+------+----------------+---+--------+-------+---------+---------+

# Column names with spaces
# select employee_id as emp_id, name, age, salary, tax, columnOne, columnTwo as 'column two' from emp_new_cols;

emp_1 = emp_new_cols.withColumnRenamed("columnTwo", "column two")
emp_1.show()

+-----------+----------------+---+--------+-------+---------+----------+
|employee_id|            name|age|  salary|    tax|columnOne|column two|
+-----------+----------------+---+--------+-------+---------+----------+
|        001|    Joe Goldberg| 30| 50000.0|10000.0|        1|       Two|
|        002|  Dwight Schrute| 40| 90000.0|18000.0|        1|       Two|
|        003|Marianne Bellamy|320| 10000.0| 2000.0|        1|       Two|
|        004|   Monica Gellar| 26| 75000.0|15000.0|        1|       Two|
|        005|  Joey Tribianni| 32|  5000.0| 1000.0|        1|       Two|
|        006|   Chandler Bing| 31|100000.0|20000.0|        1|       Two|
|        007|     Ross Gellar| 30|150000.0|30000.0|        1|       Two|
|        008|    Rachel Green| 29| 50000.0|10000.0|        1|       Two|
|        009|   Pheebi Buffay| 30| 10000.0| 2000.0|        1|       Two|
|        010|  Peach Salinger| 32|200000.0|40000.0|        1|       Two|
|        011|   Michael Scott| 40| 80000.0|16000.0|        1|       Two|
|        012|   Donald Draper| 35| 90000.0|18000.0|        1|       Two|
|        013|  Roger Sterling| 60|300000.0|60000.0|        1|       Two|
+-----------+----------------+---+--------+-------+---------+----------+

-- Removing column :

# Remove columns

emp_dropped = emp_new_cols.drop("columnOne")
emp_dropped.show()

+-----------+----------------+---+--------+-------+---------+
|employee_id|            name|age|  salary|    tax|columnTwo|
+-----------+----------------+---+--------+-------+---------+
|        001|    Joe Goldberg| 30| 50000.0|10000.0|      Two|
|        002|  Dwight Schrute| 40| 90000.0|18000.0|      Two|
|        003|Marianne Bellamy|320| 10000.0| 2000.0|      Two|
|        004|   Monica Gellar| 26| 75000.0|15000.0|      Two|
|        005|  Joey Tribianni| 32|  5000.0| 1000.0|      Two|
|        006|   Chandler Bing| 31|100000.0|20000.0|      Two|
|        007|     Ross Gellar| 30|150000.0|30000.0|      Two|
|        008|    Rachel Green| 29| 50000.0|10000.0|      Two|
|        009|   Pheebi Buffay| 30| 10000.0| 2000.0|      Two|
|        010|  Peach Salinger| 32|200000.0|40000.0|      Two|
|        011|   Michael Scott| 40| 80000.0|16000.0|      Two|
|        012|   Donald Draper| 35| 90000.0|18000.0|      Two|
|        013|  Roger Sterling| 60|300000.0|60000.0|      Two|
+-----------+----------------+---+--------+-------+---------+

-- Filter : 

# filter data
# select employee_id as emp_id, name, age, salary, tax, columnOne, columnTwo as 'column two' from emp_dropped where tax > 10000;

emp_filtered = emp_dropped.where("tax > 10000")
emp_filtered.show()

+-----------+--------------+---+--------+-------+---------+
|employee_id|          name|age|  salary|    tax|columnTwo|
+-----------+--------------+---+--------+-------+---------+
|        002|Dwight Schrute| 40| 90000.0|18000.0|      Two|
|        004| Monica Gellar| 26| 75000.0|15000.0|      Two|
|        006| Chandler Bing| 31|100000.0|20000.0|      Two|
|        007|   Ross Gellar| 30|150000.0|30000.0|      Two|
|        010|Peach Salinger| 32|200000.0|40000.0|      Two|
|        011| Michael Scott| 40| 80000.0|16000.0|      Two|
|        012| Donald Draper| 35| 90000.0|18000.0|      Two|
|        013|Roger Sterling| 60|300000.0|60000.0|      Two|
+-----------+--------------+---+--------+-------+---------+

-- For limit :

# Limit data
# select employee_id as emp_id, name, age, salary, tax, columnTwo as 'column two' from emp_filtered LIMIT 5;

emp_limit = emp_filtered.limit(5)
emp_limit.show()

+-----------+--------------+---+--------+-------+---------+
|employee_id|          name|age|  salary|    tax|columnTwo|
+-----------+--------------+---+--------+-------+---------+
|        002|Dwight Schrute| 40| 90000.0|18000.0|      Two|
|        004| Monica Gellar| 26| 75000.0|15000.0|      Two|
|        006| Chandler Bing| 31|100000.0|20000.0|      Two|
|        007|   Ross Gellar| 30|150000.0|30000.0|      Two|
|        010|Peach Salinger| 32|200000.0|40000.0|      Two|
+-----------+--------------+---+--------+-------+---------+

****** BONUS TIP ******

# Bonus tip
# Add multiple columns

columns = {
    "tax": col("salary") * 0.2,
    "oneNumber": lit(1),
    "twoNumber": lit("two")
}

emp_final = emp.withColumns(columns)
emp_final.show()

